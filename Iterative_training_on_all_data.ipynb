{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omri/my_gpu/.env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def config_paths(user, env_name):\n",
    "    paths = ['',\n",
    "             '/home/{0}/{1}/.env/bin'.format(user, env_name),\n",
    "             '/usr/lib/python35.zip',\n",
    "             '/usr/lib/python3.5',\n",
    "             '/usr/lib/python3.5/plat-x86_64-linux-gnu',\n",
    "             '/usr/lib/python3.5/lib-dynload',\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages'.format(user, env_name),\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages/IPython/extensions'.format(user, env_name),\n",
    "             '/home/{0}/.ipython']\n",
    "\n",
    "    for path in paths:\n",
    "        sys.path.append(path)\n",
    "        \n",
    "config_paths('omri', 'my_gpu')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "TRAIN_DIR = '../'\n",
    "K = 20\n",
    "SAMPLE_NUM = 128 * K   \n",
    "IMG_SIZE = 224\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "else:\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                     pooling=None, classes=128)\n",
    "\n",
    "    last = model.output\n",
    "\n",
    "    x = Flatten()(last)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "    model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_chunk(model, chunk_number):\n",
    "    global K\n",
    "    global TRAIN_DIR\n",
    "    global SAMPLE_NUM\n",
    "    global IMG_SIZE\n",
    "    X_total = np.zeros(shape = (SAMPLE_NUM, IMG_SIZE,IMG_SIZE,3))\n",
    "    Y_total = np.zeros(shape = (SAMPLE_NUM,))\n",
    "\n",
    "    for category_ind in range(1,129):\n",
    "        cagetory_dir = os.path.join(TRAIN_DIR, str(category_ind))\n",
    "\n",
    "        cur_image_list = os.listdir(cagetory_dir)\n",
    "        if (chunk_number+1)*K > len(cur_image_list):\n",
    "            temp_list = cur_image_list[chunk_number*K:]\n",
    "        else:\n",
    "            temp_list = cur_image_list[chunk_number*K:(chunk_number+1)*K]\n",
    "        for im_ind, im_name in enumerate(temp_list):\n",
    "            im = cv2.imread(os.path.join(cagetory_dir, im_name))\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "            im = im/255.0\n",
    "\n",
    "            X_total[(category_ind-1)*K + im_ind] = im\n",
    "            Y_total[(category_ind-1)*K + im_ind] = category_ind - 1\n",
    "\n",
    "    random_indices = np.random.permutation(SAMPLE_NUM)\n",
    "    X_total = X_total[random_indices]\n",
    "    Y_total = Y_total[random_indices]\n",
    "\n",
    "    train_num = int(SAMPLE_NUM * 0.7)\n",
    "    X_train = X_total[:train_num]\n",
    "    Y_train = Y_total[:train_num]\n",
    "\n",
    "    X_val = X_total[train_num:]\n",
    "    Y_val = Y_total[train_num:]\n",
    "\n",
    "    Y_val = np_utils.to_categorical(Y_val,128)\n",
    "    Y_train = np_utils.to_categorical(Y_train,128)\n",
    "\n",
    "    \n",
    "    earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "    checkpointer = ModelCheckpoint('model_iter_dropout.h5', verbose=1, save_best_only=True)\n",
    "    \n",
    "    epochs = 30\n",
    "    learning_rate = 0.001\n",
    "    decay_rate = learning_rate / epochs\n",
    "\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False, decay=0)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=32, \n",
    "              nb_epoch=epochs,verbose=1,\n",
    "              validation_data=(X_val, Y_val), callbacks=[earlystopper, checkpointer])\n",
    "    \n",
    "    \n",
    "    \n",
    "for chunk in range(10):\n",
    "    train_on_chunk(model, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_iter_dropout.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model_iter_dropout.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
