{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omri/my_gpu/.env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def config_paths(user, env_name):\n",
    "    paths = ['',\n",
    "             '/home/{0}/{1}/.env/bin'.format(user, env_name),\n",
    "             '/usr/lib/python35.zip',\n",
    "             '/usr/lib/python3.5',\n",
    "             '/usr/lib/python3.5/plat-x86_64-linux-gnu',\n",
    "             '/usr/lib/python3.5/lib-dynload',\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages'.format(user, env_name),\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages/IPython/extensions'.format(user, env_name),\n",
    "             '/home/{0}/.ipython']\n",
    "\n",
    "    for path in paths:\n",
    "        sys.path.append(path)\n",
    "        \n",
    "config_paths('omri', 'my_gpu')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "TRAIN_DIR = '../'\n",
    "K = 30\n",
    "SAMPLE_NUM = 128 * K   \n",
    "IMG_SIZE = 197\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    json_file = open('my_vgg_all_1_epoch.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"my_vgg_all_1_epoch.h5\")\n",
    "\n",
    "else:\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras import regularizers\n",
    "\n",
    "    model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                     pooling=None, classes=128)\n",
    "\n",
    "    # model = Model(model.input, preds)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    last = model.output\n",
    "\n",
    "    x = Flatten()(last)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='sigmoid',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "    model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 197, 197, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 197, 197, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 197, 197, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 98, 98, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 98, 98, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 49, 49, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "=================================================================\n",
      "Total params: 24,218,048\n",
      "Trainable params: 9,503,360\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "def train_on_chunk(model, chunk_number, X_validation='', Y_validation=''):\n",
    "    global K\n",
    "    global TRAIN_DIR\n",
    "    global SAMPLE_NUM\n",
    "    global IMG_SIZE\n",
    "    X_train = np.zeros(shape = (SAMPLE_NUM, IMG_SIZE,IMG_SIZE,3))\n",
    "    Y_train = np.zeros(shape = (SAMPLE_NUM,))\n",
    "\n",
    "    for category_ind in range(1,129):\n",
    "        cagetory_dir = os.path.join(TRAIN_DIR, str(category_ind))\n",
    "\n",
    "        cur_image_list = os.listdir(cagetory_dir)\n",
    "        if (chunk_number+1)*K > len(cur_image_list):\n",
    "            temp_list = cur_image_list[chunk_number*K:]\n",
    "        else:\n",
    "            temp_list = cur_image_list[chunk_number*K:(chunk_number+1)*K]\n",
    "        for im_ind, im_name in enumerate(temp_list):\n",
    "            im = cv2.imread(os.path.join(cagetory_dir, im_name))\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "            im = im/255.0\n",
    "\n",
    "            X_train[(category_ind-1)*K + im_ind] = im\n",
    "            Y_train[(category_ind-1)*K + im_ind] = category_ind - 1\n",
    "\n",
    "    random_indices = np.random.permutation(SAMPLE_NUM)\n",
    "#     X_total = X_total[random_indices]\n",
    "#     Y_total = Y_total[random_indices]\n",
    "    \n",
    "    # Get Validation from first iteration\n",
    "    if chunk_number == 0:\n",
    "        return X_train, np_utils.to_categorical(Y_train,128)\n",
    "    \n",
    "    # If not first iteration, continue training\n",
    "    else:\n",
    "        train_num = int(SAMPLE_NUM * 1)\n",
    "        Y_train = np_utils.to_categorical(Y_train,128)\n",
    "        X_val = X_validation\n",
    "        Y_val = Y_validation\n",
    "\n",
    "    \n",
    "    earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "    checkpointer = ModelCheckpoint('model_iter_dropout.h5', verbose=1, save_best_only=True)\n",
    "    \n",
    "    epochs = 1\n",
    "#     learning_rate = 0.001\n",
    "#     decay_rate = learning_rate / epochs\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # model.fit_generator(image_gen.flow(X_train, Y_train, batch_size=32),\n",
    "    #           epochs=40,\n",
    "    #           verbose=1,\n",
    "    #           class_weight=class_weight,\n",
    "    #             validation_data=(X_val, Y_val))\n",
    "\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=32, \n",
    "              epochs=epochs,verbose=1, validation_data=(X_val, Y_val), callbacks=[earlystopper])\n",
    "   \n",
    "\n",
    "    \n",
    "for i in range(100):    \n",
    "    for chunk in range(30) :\n",
    "        print(i, chunk)\n",
    "        if (chunk == 0) & (i == 0):\n",
    "            X_val, Y_val = train_on_chunk(model, chunk)\n",
    "        else:\n",
    "            train_on_chunk(model, chunk, X_val, Y_val)\n",
    "        \n",
    "        model_json = model.to_json()\n",
    "        with open(\"my_vgg_all_1_epoch_2.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        model.save_weights(\"my_vgg_all_2_epoch_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"my_vgg_all_1_epoch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"my_vgg_all_1_epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
