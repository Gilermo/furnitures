{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some weird config required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def config_paths(user, env_name):\n",
    "    paths = ['',\n",
    "             '/home/{0}/{1}/.env/bin'.format(user, env_name),\n",
    "             '/usr/lib/python35.zip',\n",
    "             '/usr/lib/python3.5',\n",
    "             '/usr/lib/python3.5/plat-x86_64-linux-gnu',\n",
    "             '/usr/lib/python3.5/lib-dynload',\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages'.format(user, env_name),\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages/IPython/extensions'.format(user, env_name),\n",
    "             '/home/{0}/.ipython']\n",
    "\n",
    "    for path in paths:\n",
    "        sys.path.append(path)\n",
    "        \n",
    "config_paths('omri', 'my_gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omri/my_gpu/.env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../'\n",
    "K = 20\n",
    "SAMPLE_NUM = 128 * K   \n",
    "IMG_SIZE = 197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.zeros(shape = (SAMPLE_NUM, IMG_SIZE,IMG_SIZE,3))\n",
    "Y_total = np.zeros(shape = (SAMPLE_NUM,))\n",
    "\n",
    "for category_ind in range(1,129):\n",
    "    cagetory_dir = os.path.join(TRAIN_DIR, str(category_ind))\n",
    "    \n",
    "    cur_image_list = os.listdir(cagetory_dir)\n",
    "    for im_ind, im_name in enumerate(cur_image_list[:K]):\n",
    "        im = cv2.imread(os.path.join(cagetory_dir, im_name))\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "        im = im/255.0\n",
    "        \n",
    "        X_total[(category_ind-1)*K + im_ind] = im\n",
    "        Y_total[(category_ind-1)*K + im_ind] = category_ind - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.permutation(SAMPLE_NUM)\n",
    "X_total = X_total[random_indices]\n",
    "Y_total = Y_total[random_indices]\n",
    "\n",
    "train_num = int(SAMPLE_NUM * 0.7)\n",
    "X_train = X_total[:train_num]\n",
    "Y_train = Y_total[:train_num]\n",
    "\n",
    "X_val = X_total[train_num:]\n",
    "Y_val = Y_total[train_num:]\n",
    "\n",
    "Y_val = np_utils.to_categorical(Y_val,128)\n",
    "Y_train = np_utils.to_categorical(Y_train,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, 3, 3,\n",
    "#                     border_mode='valid',\n",
    "#                     input_shape=(IMG_SIZE, IMG_SIZE ,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# #model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# model = VGG16(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE ,3), \n",
    "#               weights='imagenet', input_tensor=None, pooling=None, classes=128)\n",
    "\n",
    "# last = model.output\n",
    "\n",
    "# x = Flatten()(last)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "# model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                 pooling=None, classes=128)\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omri/gpu_env/.env/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1792 samples, validate on 768 samples\n",
      "Epoch 1/30\n",
      "1792/1792 [==============================] - 72s 40ms/step - loss: 5.0597 - acc: 0.0078 - val_loss: 12.0603 - val_acc: 0.0013\n",
      "Epoch 2/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.8514 - acc: 0.0095 - val_loss: 9.3461 - val_acc: 0.0065\n",
      "Epoch 3/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.8422 - acc: 0.0084 - val_loss: 4.8608 - val_acc: 0.0065\n",
      "Epoch 4/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.7903 - acc: 0.0195 - val_loss: 5.0038 - val_acc: 0.0156\n",
      "Epoch 5/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.7607 - acc: 0.0229 - val_loss: 6.0467 - val_acc: 0.0078\n",
      "Epoch 6/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.7304 - acc: 0.0257 - val_loss: 5.8362 - val_acc: 0.0104\n",
      "Epoch 7/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.6413 - acc: 0.0301 - val_loss: 4.8594 - val_acc: 0.0026\n",
      "Epoch 8/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.5660 - acc: 0.0346 - val_loss: 6.6714 - val_acc: 0.0039\n",
      "Epoch 9/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.4624 - acc: 0.0379 - val_loss: 5.7554 - val_acc: 0.0130\n",
      "Epoch 10/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.4386 - acc: 0.0385 - val_loss: 4.9014 - val_acc: 0.0130\n",
      "Epoch 11/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.3561 - acc: 0.0502 - val_loss: 4.8748 - val_acc: 0.0052\n",
      "Epoch 12/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.2894 - acc: 0.0474 - val_loss: 4.8575 - val_acc: 0.0312\n",
      "Epoch 13/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.2156 - acc: 0.0530 - val_loss: 5.3655 - val_acc: 0.0195\n",
      "Epoch 14/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.2547 - acc: 0.0552 - val_loss: 5.3261 - val_acc: 0.0286\n",
      "Epoch 15/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.2121 - acc: 0.0658 - val_loss: 4.8648 - val_acc: 0.0208\n",
      "Epoch 16/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.1682 - acc: 0.0686 - val_loss: 4.8508 - val_acc: 0.0026\n",
      "Epoch 17/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 4.0365 - acc: 0.0792 - val_loss: 4.8441 - val_acc: 0.0378\n",
      "Epoch 18/30\n",
      "1792/1792 [==============================] - 53s 30ms/step - loss: 3.9923 - acc: 0.0882 - val_loss: 8.9572 - val_acc: 0.0273\n",
      "Epoch 19/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.9116 - acc: 0.0943 - val_loss: 5.2388 - val_acc: 0.0169\n",
      "Epoch 20/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.9318 - acc: 0.0971 - val_loss: 4.9389 - val_acc: 0.0156\n",
      "Epoch 21/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.8197 - acc: 0.1027 - val_loss: 4.4968 - val_acc: 0.0534\n",
      "Epoch 22/30\n",
      "1792/1792 [==============================] - 53s 30ms/step - loss: 3.7396 - acc: 0.1166 - val_loss: 4.8733 - val_acc: 0.0391\n",
      "Epoch 23/30\n",
      "1792/1792 [==============================] - 53s 30ms/step - loss: 3.6398 - acc: 0.1272 - val_loss: 5.0900 - val_acc: 0.0352\n",
      "Epoch 24/30\n",
      "1792/1792 [==============================] - 53s 30ms/step - loss: 3.6216 - acc: 0.1473 - val_loss: 4.9152 - val_acc: 0.0469\n",
      "Epoch 25/30\n",
      "1792/1792 [==============================] - 53s 30ms/step - loss: 3.5904 - acc: 0.1283 - val_loss: 5.0665 - val_acc: 0.0443\n",
      "Epoch 26/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.4803 - acc: 0.1551 - val_loss: 4.7487 - val_acc: 0.0625\n",
      "Epoch 27/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.4077 - acc: 0.1602 - val_loss: 4.8879 - val_acc: 0.0495\n",
      "Epoch 28/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.4309 - acc: 0.1613 - val_loss: 4.3787 - val_acc: 0.0638\n",
      "Epoch 29/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.2272 - acc: 0.1886 - val_loss: 6.9161 - val_acc: 0.0299\n",
      "Epoch 30/30\n",
      "1792/1792 [==============================] - 54s 30ms/step - loss: 3.0952 - acc: 0.2037 - val_loss: 5.9079 - val_acc: 0.0495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f392f766438>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, \n",
    "          nb_epoch=30,verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, accuracy = model.evaluate(X_val, Y_val, verbose=1)\n",
    "predictions = model.predict(X_val)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape = (12800, IMG_SIZE,IMG_SIZE,3))\n",
    "indices = np.zeros(12800)\n",
    "test_path = '../test'\n",
    "files_list = os.listdir(test_path)\n",
    "for im_ind, im_name in enumerate(files_list):\n",
    "    im = cv2.imread(os.path.join(test_path, im_name))\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "    im = im/255.0\n",
    "    img_ind = int(im_name.split('.')[0])\n",
    "    indices[im_ind] = img_ind\n",
    "    X_test[im_ind] = im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_imgs = set(range(12800)) - set(indices)\n",
    "for i, loc in enumerate(np.where(indices==0)[0]):\n",
    "    indices[loc] = list(missing_imgs)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(X_test)\n",
    "y_test = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resnet_big.csv'\n",
    "ans = pd.DataFrame({'id': [int(x) for x in indices],\n",
    "                    'predicted': [int(x) for x in y_test + np.ones(len(y_test))]})\n",
    "\n",
    "ans.sort_values(by='id').to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
