{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some weird config required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def config_paths(user, env_name):\n",
    "    paths = ['',\n",
    "             '/home/{0}/{1}/.env/bin'.format(user, env_name),\n",
    "             '/usr/lib/python35.zip',\n",
    "             '/usr/lib/python3.5',\n",
    "             '/usr/lib/python3.5/plat-x86_64-linux-gnu',\n",
    "             '/usr/lib/python3.5/lib-dynload',\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages'.format(user, env_name),\n",
    "             '/home/{0}/{1}/.env/lib/python3.5/site-packages/IPython/extensions'.format(user, env_name),\n",
    "             '/home/{0}/.ipython']\n",
    "\n",
    "    for path in paths:\n",
    "        sys.path.append(path)\n",
    "        \n",
    "config_paths('omri', 'my_gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omri/my_gpu/.env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../'\n",
    "K = 20\n",
    "SAMPLE_NUM = 128 * K   \n",
    "IMG_SIZE = 197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.zeros(shape = (SAMPLE_NUM, IMG_SIZE,IMG_SIZE,3))\n",
    "Y_total = np.zeros(shape = (SAMPLE_NUM,))\n",
    "\n",
    "for category_ind in range(1,129):\n",
    "    cagetory_dir = os.path.join(TRAIN_DIR, str(category_ind))\n",
    "    \n",
    "    cur_image_list = os.listdir(cagetory_dir)\n",
    "    for im_ind, im_name in enumerate(cur_image_list[:K]):\n",
    "        im = cv2.imread(os.path.join(cagetory_dir, im_name))\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "        im = im/255.0\n",
    "        \n",
    "        X_total[(category_ind-1)*K + im_ind] = im\n",
    "        Y_total[(category_ind-1)*K + im_ind] = category_ind - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.permutation(SAMPLE_NUM)\n",
    "X_total = X_total[random_indices]\n",
    "Y_total = Y_total[random_indices]\n",
    "\n",
    "train_num = int(SAMPLE_NUM * 0.7)\n",
    "X_train = X_total[:train_num]\n",
    "Y_train = Y_total[:train_num]\n",
    "\n",
    "X_val = X_total[train_num:]\n",
    "Y_val = Y_total[train_num:]\n",
    "\n",
    "Y_val = np_utils.to_categorical(Y_val,128)\n",
    "Y_train = np_utils.to_categorical(Y_train,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, 3, 3,\n",
    "#                     border_mode='valid',\n",
    "#                     input_shape=(IMG_SIZE, IMG_SIZE ,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# #model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# model = VGG16(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE ,3), \n",
    "#               weights='imagenet', input_tensor=None, pooling=None, classes=128)\n",
    "\n",
    "# last = model.output\n",
    "\n",
    "# x = Flatten()(last)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "# model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                 pooling=None, classes=128)\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "preds = Dense(128, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, \n",
    "          nb_epoch=30,verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, accuracy = model.evaluate(X_val, Y_val, verbose=1)\n",
    "predictions = model.predict(X_val)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape = (12800, IMG_SIZE,IMG_SIZE,3))\n",
    "indices = np.zeros(12800)\n",
    "test_path = '../test'\n",
    "files_list = os.listdir(test_path)\n",
    "for im_ind, im_name in enumerate(files_list):\n",
    "    im = cv2.imread(os.path.join(test_path, im_name))\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (IMG_SIZE, IMG_SIZE))\n",
    "    im = im/255.0\n",
    "    img_ind = int(im_name.split('.')[0])\n",
    "    indices[im_ind] = img_ind\n",
    "    X_test[im_ind] = im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_imgs = set(range(12800)) - set(indices)\n",
    "for i, loc in enumerate(np.where(indices==0)[0]):\n",
    "    indices[loc] = list(missing_imgs)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(X_test)\n",
    "y_test = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resnet_big.csv'\n",
    "ans = pd.DataFrame({'id': [int(x) for x in indices],\n",
    "                    'predicted': [int(x) for x in y_test + np.ones(len(y_test))]})\n",
    "\n",
    "ans.sort_values(by='id').to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
